import streamlit as st
from langchain_community.chat_models import ChatZhipuAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.callbacks.base import BaseCallbackHandler
from langchain_core.callbacks.manager import CallbackManager
import os
from dotenv import load_dotenv
import asyncio

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨ï¼Œç”¨äºå¤„ç†æµå¼è¾“å‡º
class StreamlitCallbackHandler(BaseCallbackHandler):
    def __init__(self, container):
        self.container = container
        self.text = ""

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """æ¯æ¬¡æ”¶åˆ°æ–°tokenæ—¶è°ƒç”¨"""
        self.text += token
        self.container.markdown(self.text + "â–Œ")  # æ·»åŠ å…‰æ ‡æ•ˆæœ

    def on_llm_end(self, response, **kwargs) -> None:
        """LLMè¾“å‡ºç»“æŸæ—¶è°ƒç”¨"""
        self.container.markdown(self.text)  # ç§»é™¤å…‰æ ‡ï¼Œæ˜¾ç¤ºå®Œæ•´æ–‡æœ¬


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIèŠå¤©æœºå™¨äºº",
    page_icon="ğŸ¤–",
    layout="centered"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []


def initialize_chat_model(streaming_callback=None):
    """åˆå§‹åŒ–èŠå¤©æ¨¡å‹"""
    try:
        api_key = os.getenv('ZHIPUAI_API_KEY') or st.secrets.get("ZHIPUAI_API_KEY", "")

        if not api_key:
            st.error("âš ï¸ è¯·å…ˆè®¾ç½®ZHIPUAI_API_KEYç¯å¢ƒå˜é‡æˆ–åœ¨Secretsä¸­é…ç½®")
            return None

        # åˆ›å»ºå›è°ƒç®¡ç†å™¨
        callback_manager = None
        if streaming_callback:
            callback_manager = CallbackManager([streaming_callback])

        chat = ChatZhipuAI(
            model="glm-4",
            api_key=api_key,
            temperature=0.7,
            top_p=0.9,
            streaming=True,  # å¯ç”¨æµå¼è¾“å‡º
            callback_manager=callback_manager,  # ä½¿ç”¨callback_managerè€Œä¸æ˜¯callbacks
        )
        return chat
    except Exception as e:
        st.error(f"åˆå§‹åŒ–æ¨¡å‹å¤±è´¥: {str(e)}")
        return None


def get_streaming_response(user_input, message_placeholder):
    """è·å–æµå¼å“åº” - ä¿®æ­£ç‰ˆæœ¬"""
    try:
        # åˆ›å»ºå›è°ƒå¤„ç†å™¨
        callback_handler = StreamlitCallbackHandler(message_placeholder)

        # åˆå§‹åŒ–æ¨¡å‹æ—¶ä¼ å…¥å›è°ƒå¤„ç†å™¨
        chat = initialize_chat_model(streaming_callback=callback_handler)
        if not chat:
            return False

        # æ„å»ºæ¶ˆæ¯å†å²
        messages = [
            ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­æ°”å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å›ç­”è¦ç®€æ´æ˜äº†ã€‚")
        ]

        # æ·»åŠ ä¸Šä¸‹æ–‡æ¶ˆæ¯ï¼ˆæœ€è¿‘5è½®å¯¹è¯ï¼‰
        recent_messages = st.session_state.messages[-10:]  # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
        for msg in recent_messages:
            if msg["role"] == "user":
                messages.append(("human", msg["content"]))
            else:
                messages.append(("ai", msg["content"]))

        # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
        messages.append(("human", user_input))

        # åˆ›å»ºæç¤ºæ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages(messages)

        # æ–¹æ³•1: ä½¿ç”¨ invoke æ–¹æ³•ï¼ˆæ¨èï¼‰
        chain = prompt | chat

        # è°ƒç”¨æ¨¡å‹ï¼ˆæµå¼ï¼‰
        response = chain.invoke({})

        # è¿”å›å®Œæ•´çš„å“åº”å†…å®¹
        return response.content if hasattr(response, 'content') else str(response)

    except Exception as e:
        message_placeholder.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        return False


# å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨æ›´ç®€å•çš„æ–¹æ³•
def get_streaming_response_simple(user_input, message_placeholder):
    """ç®€åŒ–ç‰ˆæœ¬çš„æµå¼å“åº”"""
    try:
        # åˆ›å»ºå›è°ƒå¤„ç†å™¨
        callback_handler = StreamlitCallbackHandler(message_placeholder)

        # åˆå§‹åŒ–æ¨¡å‹
        chat = ChatZhipuAI(
            model="glm-4",
            api_key=os.getenv('ZHIPUAI_API_KEY') or st.secrets.get("ZHIPUAI_API_KEY", ""),
            temperature=0.7,
            top_p=0.9,
            streaming=True,
            callbacks=[callback_handler],  # åœ¨æŸäº›ç‰ˆæœ¬ä¸­è¿™æ ·ä½¿ç”¨
        )

        if not chat:
            return False

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        message_list = []

        # æ·»åŠ ä¸Šä¸‹æ–‡
        recent_messages = st.session_state.messages[-8:]
        for msg in recent_messages:
            if msg["role"] == "user":
                message_list.append(("human", msg["content"]))
            else:
                message_list.append(("ai", msg["content"]))

        # æ·»åŠ å½“å‰æ¶ˆæ¯
        message_list.append(("human", user_input))

        # åˆ›å»ºæç¤º
        prompt = ChatPromptTemplate.from_messages(
            [("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹")] + message_list
        )

        # ä½¿ç”¨ LCEL (LangChain Expression Language)
        chain = prompt | chat

        # è°ƒç”¨é“¾
        response = chain.invoke({})

        return response.content

    except Exception as e:
        message_placeholder.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        return False


# æœ€ç»ˆè§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨æœ€å…¼å®¹çš„æ–¹å¼
def get_streaming_response_final(user_input, message_placeholder):
    """æœ€ç»ˆå…¼å®¹ç‰ˆæœ¬çš„æµå¼å“åº”"""
    try:
        api_key = os.getenv('ZHIPUAI_API_KEY') or st.secrets.get("ZHIPUAI_API_KEY", "")
        if not api_key:
            message_placeholder.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥")
            return False

        # åˆ›å»ºå›è°ƒå¤„ç†å™¨
        callback_handler = StreamlitCallbackHandler(message_placeholder)

        # ç›´æ¥åˆå§‹åŒ–æ¨¡å‹
        llm = ChatZhipuAI(
            model="glm-4",
            api_key=api_key,
            temperature=0.7,
            top_p=0.9,
            streaming=True,
            callbacks=[callback_handler],
        )

        # æ„å»ºå¯¹è¯å†å²
        conversation_history = []
        for msg in st.session_state.messages[-6:]:  # é™åˆ¶å†å²é•¿åº¦
            if msg["role"] == "user":
                conversation_history.append(f"ç”¨æˆ·: {msg['content']}")
            else:
                conversation_history.append(f"åŠ©æ‰‹: {msg['content']}")

        # æ„å»ºå®Œæ•´çš„æç¤º
        if conversation_history:
            history_text = "\n".join(conversation_history)
            full_prompt = f"{history_text}\nç”¨æˆ·: {user_input}\nåŠ©æ‰‹: "
        else:
            full_prompt = f"ç”¨æˆ·: {user_input}\nåŠ©æ‰‹: "

        # ç›´æ¥è°ƒç”¨æ¨¡å‹
        response = llm.invoke(full_prompt)

        return response.content

    except Exception as e:
        message_placeholder.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        return False


# é¡µé¢æ ‡é¢˜å’Œæè¿°
st.title("ğŸ¤– AIèŠå¤©æœºå™¨äºº")
st.markdown("---")
st.markdown("ä½“éªŒå®æ—¶å¯¹è¯ï¼Œæ„Ÿå—æ›´è‡ªç„¶çš„äº¤æµæ–¹å¼ï¼")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ é…ç½®")

    # APIå¯†é’¥è¾“å…¥
    if not os.getenv('ZHIPUAI_API_KEY'):
        api_key_input = st.text_input(
            "æ™ºè°±AI APIå¯†é’¥",
            type="password",
            placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„APIå¯†é’¥",
            help="æ‚¨å¯ä»¥åœ¨æ™ºè°±AIå¼€æ”¾å¹³å°è·å–APIå¯†é’¥"
        )
        if api_key_input:
            os.environ['ZHIPUAI_API_KEY'] = api_key_input
            st.success("âœ… APIå¯†é’¥å·²è®¾ç½®")

    # å“åº”æ–¹æ³•é€‰æ‹©
    st.subheader("å“åº”æ¨¡å¼")
    response_mode = st.radio(
        "é€‰æ‹©å“åº”æ–¹å¼",
        ["ç®€åŒ–æ¨¡å¼", "å…¼å®¹æ¨¡å¼"],
        index=1,
        help="å¦‚æœä¸€ç§æ¨¡å¼ä¸å·¥ä½œï¼Œè¯·å°è¯•å¦ä¸€ç§"
    )

    st.markdown("---")
    st.subheader("ğŸ’¡ ä½¿ç”¨æç¤º")
    st.markdown("""
    - ğŸ’¬ è¾“å…¥é—®é¢˜ï¼Œä½“éªŒå®æ—¶å›ç­”
    - â³ é•¿å›ç­”ä¼šæœ‰æ˜æ˜¾çš„æ‰“å­—æœºæ•ˆæœ
    - ğŸ”„ æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡
    - ğŸ—‘ï¸ å¯éšæ—¶æ¸…ç©ºå¯¹è¯å†å²
    """)

    # æ¸…é™¤å¯¹è¯æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# æ˜¾ç¤ºèŠå¤©æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# èŠå¤©è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¼šè¯çŠ¶æ€
    st.session_state.messages.append({"role": "user", "content": prompt})

    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)

    # æ˜¾ç¤ºAIå›å¤ï¼ˆæµå¼ï¼‰
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        # æ ¹æ®é€‰æ‹©çš„æ¨¡å¼è°ƒç”¨ä¸åŒçš„æ–¹æ³•
        if response_mode == "ç®€åŒ–æ¨¡å¼":
            full_response = get_streaming_response_simple(prompt, message_placeholder)
        else:
            full_response = get_streaming_response_final(prompt, message_placeholder)

        if full_response:
            # ç¡®ä¿æ¶ˆæ¯å®Œå…¨æ˜¾ç¤º
            message_placeholder.markdown(full_response)
            # æ·»åŠ AIå›å¤åˆ°ä¼šè¯çŠ¶æ€
            st.session_state.messages.append({"role": "assistant", "content": full_response})

# åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.caption("ğŸš€ Powered by LangChain 1.0.4 + æ™ºè°±AI GLM-4 + Streamlit")
st.caption("âœ¨ å®æ—¶è¾“å‡º | å¤šè½®å¯¹è¯ | å…¼å®¹æ€§ä¼˜åŒ–")

# ç©ºçŠ¶æ€æç¤º
if not st.session_state.messages:
    st.info("ğŸ‘† åœ¨ä¸Šæ–¹è¾“å…¥æ¡†å¼€å§‹æ‚¨çš„å¯¹è¯ï¼Œä½“éªŒæµå¼å›ç­”æ•ˆæœï¼")